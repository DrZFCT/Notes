\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,total={6in,10in}]{geometry}
\usepackage{amsmath}
\usepackage{mathrsfs}

\usepackage{amsthm}

\newtheorem{Thm}{Theorem}[section]
\newtheorem{Cor}{Corollary}[Thm]
\newtheorem{Lem}{Lemma}[section]
\newtheorem{Eg}{Example}[section]
\newtheorem*{Rk}{Remark}

\theoremstyle{definition}
\newtheorem{Def}{Definition}[section]


\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}

\renewcommand{\AA}{\mathbb{A}}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\DD}{\mathbb{D}}
\newcommand{\EE}{\operatorname{\mathbb{E}}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\II}{\mathbb{I}}
\newcommand{\JJ}{\mathbb{J}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\LL}{\mathbb{L}}
\newcommand{\MM}{\mathbb{M}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\OO}{\mathbb{O}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\renewcommand{\SS}{\mathbb{S}}
\newcommand{\TT}{\mathbb{T}}
\newcommand{\UU}{\mathbb{U}}
\newcommand{\VV}{\mathbb{V}}
\newcommand{\WW}{\mathbb{W}}
\newcommand{\XX}{\mathbb{X}}
\newcommand{\YY}{\mathbb{Y}}
\newcommand{\ZZ}{\mathbb{Z}}


\newcommand{\fbf}[1]{\mathbf{#1}}

\newcommand{\bA}{\fbf{A}}
\newcommand{\bB}{\fbf{B}}
\newcommand{\bC}{\fbf{C}}
\newcommand{\bD}{\fbf{D}}
\newcommand{\bE}{\fbf{E}}
\newcommand{\bF}{\fbf{F}}
\newcommand{\bG}{\fbf{G}}
\newcommand{\bH}{\fbf{H}}
\newcommand{\bI}{\fbf{I}}
\newcommand{\bJ}{\fbf{J}}
\newcommand{\bK}{\fbf{K}}
\newcommand{\bL}{\fbf{L}}
\newcommand{\bM}{\fbf{M}}
\newcommand{\bN}{\fbf{N}}
\newcommand{\bO}{\fbf{Q}}
\newcommand{\bP}{\fbf{P}}
\newcommand{\bQ}{\fbf{Q}}
\newcommand{\bR}{\fbf{R}}
\newcommand{\bS}{\fbf{S}}
\newcommand{\bT}{\fbf{T}}
\newcommand{\bU}{\fbf{U}}
\newcommand{\bV}{\fbf{V}}
\newcommand{\bW}{\fbf{W}}
\newcommand{\bX}{\fbf{X}}
\newcommand{\bY}{\fbf{Y}}
\newcommand{\bZ}{\fbf{Z}}



\newcommand{\ba}{\fbf{a}}
\newcommand{\bb}{\fbf{b}}
\newcommand{\bc}{\fbf{c}}
\newcommand{\bd}{\fbf{d}}
\newcommand{\be}{\mathrm{\fbf{e}}}
\newcommand{\bmf}{\fbf{f}}
\newcommand{\bg}{\fbf{g}}
\newcommand{\bh}{\bar{h}}
\newcommand{\bi}{\fbf{i}}
\newcommand{\bj}{\fbf{j}}
\newcommand{\bl}{\fbf{l}}
\newcommand{\bmm}{\fbf{m}}
\newcommand{\bk}{\fbf{k}}
\newcommand{\bo}{\fbf{o}}
\newcommand{\bp}{\fbf{p}}
\newcommand{\bq}{\fbf{q}}
\newcommand{\br}{\fbf{r}}
\newcommand{\bs}{\fbf{s}}
\newcommand{\bt}{\fbf{t}}
\newcommand{\bu}{\fbf{u}}
\newcommand{\bv}{\fbf{v}}
\newcommand{\bw}{\fbf{w}}
\newcommand{\bx}{\fbf{x}}
\newcommand{\by}{\fbf{y}}
\newcommand{\bz}{\fbf{z}}
\DeclareMathOperator*{\argmin}{argmin}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\newcommand{\balpha}{\bm{\alpha}}
\newcommand{\bbeta}{\bm{\beta}}
\newcommand{\bgamma}{\bm{\gamma}}
\newcommand{\bomega}{\bm{\omega}}
\newcommand{\bpsi}{\bm{\psi}}
\newcommand{\bxi}{\bm{\xi}}
\newcommand{\bpi}{\bm{\pi}}
\newcommand{\bepsilon}{\bm{\epsilon}}
\newcommand{\bvarepsilon}{\bm{\varepsilon}}


\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}

\newcommand{\cOmega}{\mathcal{\Omega}}

\newcommand{\ha}{\hat{a}}
\newcommand{\hb}{\hat{b}}
\newcommand{\hc}{\hat{c}}
\newcommand{\hd}{\hat{d}}
\newcommand{\he}{\hat{e}}
\newcommand{\hf}{\hat{f}}
\newcommand{\hg}{\hat{g}}
\newcommand{\hh}{\hat{h}}
\newcommand{\hi}{\hat{i}}
\newcommand{\hj}{\hat{j}}
\newcommand{\hk}{\hat{k}}
\newcommand{\hhl}{\hat{l}}
\newcommand{\hhm}{\hat{m}}
\newcommand{\hn}{\hat{n}}
\newcommand{\ho}{\hat{o}}
\newcommand{\hp}{\hat{p}}
\newcommand{\hq}{\hat{q}}
\newcommand{\hr}{\hat{r}}
\newcommand{\hs}{\hat{s}}
\newcommand{\hht}{\hat{t}}
\newcommand{\hu}{\hat{u}}
\newcommand{\hv}{\hat{v}}
\newcommand{\hw}{\hat{w}}
\newcommand{\hx}{\hat{x}}
\newcommand{\hy}{\hat{y}}
\newcommand{\hz}{\hat{z}}


\newcommand{\hA}{\hat{A}}
\newcommand{\hB}{\hat{B}}
\newcommand{\hC}{\hat{C}}
\newcommand{\hD}{\hat{D}}
\newcommand{\hE}{\hat{E}}
\newcommand{\hF}{\hat{F}}
\newcommand{\hG}{\hat{G}}
\newcommand{\hH}{\hat{H}}
\newcommand{\hI}{\hat{I}}
\newcommand{\hJ}{\hat{J}}
\newcommand{\hK}{\hat{K}}
\newcommand{\hL}{\hat{L}}
\newcommand{\hM}{\hat{M}}
\newcommand{\hN}{\hat{N}}
\newcommand{\hO}{\hat{O}}
\newcommand{\hP}{\hat{P}}
\newcommand{\hQ}{\hat{Q}}
\newcommand{\hR}{\hat{R}}
\newcommand{\hS}{\hat{S}}
\newcommand{\hT}{\hat{T}}
\newcommand{\hU}{\hat{U}}
\newcommand{\hV}{\hat{V}}
\newcommand{\hW}{\hat{W}}
\newcommand{\hX}{\hat{X}}
\newcommand{\hY}{\hat{Y}}
\newcommand{\hZ}{\hat{Z}}


\newcommand{\htheta}{\hat{\theta}}
\newcommand{\hrho}{\hat{\rho}}

\newcommand{\transpose}{^{\operatorname{T}}}
\newcommand{\step}{\texttt{step}}
\newcommand{\relu}{\texttt{ReLU}}
\newcommand{\<}{\left\langle}
\renewcommand{\>}{\right\rangle}


\newcommand{\tri}{\mathrm{tri}}
\newcommand{\dd}{\mathop{}\!\mathrm{d}}
\newcommand{\risk}{\mathcal{R}}
\renewcommand{\ge}{\mathcal{E}}
\newcommand{\erisk}{\hat{\mathcal{R}}}
\newcommand{\wrt}{with respect to }
\newcommand{\fn}{\frac{1}{n}}
\newcommand{\fm}{\frac{1}{m}}
\newcommand{\fM}{\frac{1}{M}}
\newcommand{\sumin}{\sum_{i=1}^n}
\newcommand{\sumim}{\sum_{i=1}^m}
\newcommand{\sumjm}{\sum_{j=1}^m}
\newcommand{\sumiM}{\sum_{i=1}^M}
\newcommand{\sumjM}{\sum_{j=1}^M}
\newcommand{\sumtm}{\sum_{t=1}^m}
\newcommand{\barj}{\bar{j}}
\newcommand{\hl}{\cH_{\ell}}
\newcommand{\ttheta}{\tilde{\theta}}
\newcommand{\half}{\frac{1}{2}}

\newcommand{\de}[2]{\frac{{\rm d}#1}{{\rm d}#2}}
\newcommand{\dde}[2]{\frac{{\rm d}^2#1}{{\rm d}#2^2}}
\newcommand{\ddde}[3]{\frac{{\rm d}^2#1}{{\rm d}#2{\rm d}#3}}
\newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\ppd}[2]{\frac{\partial^2#1}{\partial#2^2}}
\newcommand{\pppd}[3]{\frac{\partial^2#1}{\partial#2\partial#3}}
% trace, rank, diag, domain
\newcommand{\tr}{{\rm tr}}
\newcommand{\rank}{{\rm rank}}
\newcommand{\diag}[1]{{\rm diag}\left(#1\right)}
\newcommand{\dom}{{\rm dom}}
% abs, norm, inner product
\newcommand{\sbra}[1]{\left(#1\right)}
\newcommand{\mbra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\norm}[2]{\left\Vert#1\right\Vert_{#2}}
\newcommand{\inn}[1]{\left\langle#1\right\rangle}
\newcommand{\cnn}{\mathrm{cnn}}
\newcommand{\lcn}{\mathrm{lcn}}
\newcommand{\fcn}{\mathrm{fcn}}

% +-infinity
\newcommand{\pif}{{+\infty}}
\newcommand{\nif}{{-\infty}}
% column vector 1
\newcommand{\one}{{\bf 1}}
% left/right hand side
\newcommand{\lhs}{\textsc{l.h.s.}}
\newcommand{\rhs}{\textsc{r.h.s.}}
% transpose
\newcommand{\tp}{^{\mathrm{T}}}
\newcommand{\ntp}{^{-\mathrm{T}}}
% projection
\newcommand{\proj}[2]{\mathrm{proj}_{#1}\left(#2\right)}
% X, x, Y, y
\newcommand{\Xbf}{\mathbf{X}}
\newcommand{\xbf}{\mathbf{x}}
\newcommand{\ybf}{\mathbf{y}}
% epsilon
\newcommand{\ep}{{\epsilon}}
\newcommand{\spg}[1]{\text{span}\{#1\}}
\newcommand{\var}{\text{Var}}


\title{Lecture Notes in Stochastic Process}
\author{Kaizhao Liu}
\date{September 2022}

\begin{document}
\maketitle
\tableofcontents
\section{Discrete Space Discrete Time Markov Chain}
\subsection{Basic Theory}
We begin by summarizing the concepts mathematicans are most interested in, and introducing their notations. 
\begin{Def}[initial distribution]
    
\end{Def}

\begin{Def}[transition matrix]
    
\end{Def}
\begin{Rk}
Transition matrix provides a way to calculate the probability that after $n$ steps the Markov chain is in a given state.
\end{Rk}
Now we focus on the class structure of markov chain.
\begin{Def}[lead to]
    We say $i$ leads to $j$ and write $i\to j$ if $P_i(X_n=j\text{ for some }n\geq 0)>0$.
\end{Def}
\begin{Def}[communicate with]
    We say $i$ communicate with $j$ and write $i\leftrightarrow j$ if both $i\to j$ and $j\to i$.
\end{Def}
\begin{Thm}[communicating classes]
    Communication is an equivalence relation on $I$, thus partition $I$ into communicating classes.
\end{Thm}
\begin{Def}[closed class]
    We say a class $C$ is closed if \[i\in C,i\to j\Longrightarrow j\in C\]
    A state $i$ is called absorbing if $\left\{i\right\}$ is a closed class.
\end{Def}
\begin{Def}[irreducibility]
    A markov chain with only one class is called irreducible.
\end{Def}



\begin{Def}[hitting time]
    Let $(X_n)_{n\geq 0}$ be a Markov chain with transition matrix $P$. The hitting time of a subset $A$ of $I$ is the random
    variable \[H^A(\omega)=\inf \left\{n\geq 0:X_n(\omega)\in A\right\}\].
\end{Def}
\begin{Def}[first passage time]
    The first passage time to state $i$ is the random variable $T_i$ defined by \[T_i(\omega)=\inf\left\{n\geq 1:X_n(\omega)=i\right\}\]
\end{Def}
\begin{Def}[$r$th passage time]
    We define $r$th passage time inductively by 
    $T_i^{(0)}(\omega)=0,T_i^{(1)}(\omega)=T_i(\omega)$
    and for $r=0,1,2,\cdots,$
    \[T_i^{(r+1)}(\omega)=\inf\left\{n\geq T_i^{(r)}(\omega)+1:X_n(\omega)=i\right\}\]
\end{Def}


\begin{Def}[absorption probability]
    The probability starting from $i$ that $(X_n)_{n\geq 0}$ ever hits $A$ is then \[h_i^A=P_i(H^A<\infty)\]
    When $A$ is a closed class, $h_i^A$ is called the absorption probability.
\end{Def}
\begin{Rk}
A less formal notation is $h_i^A=\PP(\text{hit }A)$.
\end{Rk}
\begin{Def}
    The mean time taken for $(X_n)_{n\geq 0}$ to reach $A$ from $i$ is given by \[k_i^A=E_i(H^A)=\sum_{n<\infty}nP(H^A=n)+\infty \PP(H^A=\infty)\]
\end{Def}
\begin{Rk}
    A less formal notation is $k_i^A=E_i(\text{time to hit }A)$.
\end{Rk}


\begin{Def}[recurrent]
    We say a state $i$ is recurrent if $P_i(X_n=i\text{ i.o. })=1$.
\end{Def}
\begin{Def}[transient]
    We say a state $i$ is transient if $P_i(X_n=i\text{ i.o. })=0$.
\end{Def}
\begin{Def}[positive recurrent]
    A state $i$ is postive recurrent if the expected return time $m_i=E_i(T_i)$ is finite.
    A recurrent state which fails to have this stronger property is called null recurrent.
\end{Def}
\begin{Def}[invariant measure]
    A measure is any row vector $(\lambda_i:i\in I)$ with non-negative entries. We say $\lambda$ is invariant if \[\lambda P=\lambda\]
\end{Def}
\begin{Def}[detailed balance]
    
\end{Def}

\begin{Eg}[Chip-Firing/Sand-Pile]
    Every time, pick a random $\tau$ such that $a_\tau\geq 2$ and do the update 
    \[\left\{\begin{matrix}
        a_\tau^{t+1} = a_\tau^{t} -2 \\
        a_{\tau+1}^{t+1}= a_{\tau+1}^{t}+1  \\
        a_{\tau-1}^{t+1}= a_{\tau-1}^{t}+1
        \end{matrix}\right.\]
\end{Eg}

\subsection{Ergodic Theorems}
The first topic in this section is to investigate 

Let \[N_n(y)=\sum_{m=1}^{n}1_{X_m=y} \] 
be the number of visits to $y$ by time $n$.

\begin{Thm}
    Suppose $y$ is recurrent. For any $x\in S$, as $n\to\infty$ 
    \[ \frac{N_n(y)}{n}\to \frac{1}{E_y T_y}1_{T_y<\infty} \]
\end{Thm}
\begin{proof}
    a
    \paragraph{Step 1} Suppose first we start at $x=y$. Let $R(k)=\min \{n\geq 1:N_n(y)=k \}$ and $t_k=R(k)-R(k-1)$, where $R(0)=0$.
    Then $t_i$ are i.i.d. and SLLN implies \[\frac{R(k)}{k}\to \EE_y T_y \] 

    \paragraph{Step 2} Then we generalize to $x\ne y$. The result is obviously true if $T_y=\infty$.
\end{proof}

\begin{Thm}
    Suppose $p$ is irreducible, aperiodic, and has stationary distribution $\pi$. Then as $n\to\infty$, $p^n(x,y)\to \pi(y)$.
\end{Thm}
\begin{proof}
    The proof technique is called \textbf{coupling}. Let $S^2=S\times S$. Define a transition probability $\bar{p}$ on $S\times S$ by 
    \[ \bar{p}=p((x_1,y_1),(x_2,y_2))=p(x_1,x_2)p(y_1,y_n) \] 
    i.e. each coordinate moves independently. 

    \paragraph{ $\bar{p}$ is irreducible.} This is the only step that requires aperiodicity.

    \paragraph{ $\bar{p}$ is recurrent.} This is becasue $\bar{\pi}(a,b)=\pi(a)\pi(b)$ defines a stationary distribution for $\bar{p}$. 

    Now let $(X_n,Y_n)$ denote the cahin on $S\times S$, and let $T$ be the first time that this chain hits the diagonal $\{(y,y):y\in S\}$. Let 
    $T_{(x,x)}$ be the hitting time of $(x,x)$. Since $\bar{p}$ is irreducible and recurrent, $T_{(x,x)}<\infty$ a.s. and hence $T<\infty$ a.s..

    Now we want to show the following key identity:
    \[\sum_{y}|\PP(X_n=y)-\PP(Y_n=y)|\leq 2 \PP(T>n). \] 
    This is because on $\{T\leq n\}$, the two coordinates $X_n$ and $Y_n$ have the same distribution.

    Finally we let $X_0=x$ and $Y_0\sim \pi$, then $Y_n$ has distribution $\pi$, and it follows that 
    \[\sum_{y}|p^n(x,y)-\pi(y)|\leq 2 \PP(T>n)\to 0. \] 
\end{proof}

\subsection{Introduction to Markov Chain Mixing}

\paragraph{Contraction}

\paragraph{Canonical Path}

\paragraph{Cheeger's Constant}


\section{Introduction to Markov Random Fields}
\subsection{Basics}


\subsection{Coloring}

\paragraph{Glauber Dynamics}
Every time pick a random vertex and assign a random color which is not used by any neighbors.


\subsection{1D Ising Model without Magnetic Field}
The Ising model is a theoretical model in statistical physics that was originally developed
to describe ferromagnetism, a property of certain materials such as iron. A system of magnetic particles can be modeled as a linear
chain in one dimension or a lattice in two dimension, with one molecule or atom at each
lattice site $i$. To each molecule or atom a magnetic moment is assigned that is represented
in the model by a discrete variable $\sigma_i$. Each 'spin' can only have a value of $\sigma_i = \pm 1$.
The two possible values indicate whether two spins $\sigma_i$ and $\sigma_j$ are align and thus parallel
($\sigma_i \cdot \sigma_j = +1$) or anti-parallel ($\sigma_i \cdot \sigma_j = +1$)

A system of two spins is considered to be in a lower energetic state if the two magnetic
moments are aligned. If the magnetic moments points in opposite directions they are
consider to be in a higher energetic state. Due to this interaction the system tends to
align all magnetic moments in one direction in order to minimise energy. If nearly all
magnetic moments point in the same direction the arrangement of molecules behaves like
a macroscopic magnet.

A phase transition in the context of the Ising model is a transition from an ordered state
to a disordered state. A ferromagnet above the critical temperature $T_C$ is in a disordered
state. In the Ising model this corresponds to a random distribution of the spin values.
Below the critical temperature $T_C$ (nearly) all spins are aligned, even in the absence of an
external applied magnetic field H. If we heat up a cooled ferromagnet, the magnetization
vanishes at $T_C$ and the ferromagnet switches from an ordered to a disordered state. This
is a phase transition of second order.


\subsection{1D Ising Model with Magnetic Field}

\subsection{2D Ising Model: Peirls Proof}
The Hamiltonion of the system is 
\[ \]

The idea of Peirls proof is very similar to the idea of reflection principle,
which map 


\section{Electrical Networks}
\subsection{The Correspondence}

Assume a unit voltage is charged on $a$ and $b$ is grounded, i.e. $\varphi(a)=1$ and $\varphi(b)=0$.

\paragraph{The Correspondence between Reversible Markov Chains and Electrical Networks}
Given an electrical network, we can define a corresponding reversible Markov chain as follows.
Let the \textbf{transition probability} be \[p(x,y)=\frac{C_{xy}}{C_x},\] 
where \[C_x=\sum_{y} C_{xy} .\]
This chain is indeed reversible because we can define a measure as 
\[\pi(x)=C_x,\] 
then the detailed balance condition is satisdied as 
\[\pi(x)p(x,y)= C_{xy}= C_{yx}=\pi(y)p(y,x).\]


Conversely, given a reversible Markov chain with reversible measure $\pi(x)$, i.e. $\pi(x)p(x,y)=\pi(y)p(y,x)$,
we can define a corresponding electrical network as follows.
Let \[C_{xy}=\pi(x)p(x,y),\]
then it is indeed a well-defined electrical network as 
\[C_{xy}=\pi(x)p(x,y)=\pi(y)p(y,x)=C_{yx}. \]
\paragraph{Voltage}
\begin{Thm} 
$\varphi(x)=\PP_x(\tau_a<\tau_b)$
\end{Thm}
\begin{proof}
    $\varphi(x)$ satisfies the same harmonic equation as $\PP_x(\tau_a<\tau_b)$.
    Moreover, the boundary condition is also the same.
\end{proof}


\paragraph{Electrical Current}
\begin{Thm}
    $I(x,y)=?$
\end{Thm}
\begin{proof}
    \begin{align*}
        I(x,y)&=C_{xy}(\varphi(x)-\varphi(y))
    \end{align*}
\end{proof}

\paragraph{Effective Resistance} 
\begin{Def}[effective resistance]
    $R_{\text{eff}}=\frac{1}{I(a^+)}$
\end{Def}

\begin{Thm}
    $\PP_b(\tau_a<\sigma_b)=\frac{1}{C_bR_{\text{eff}}}$
\end{Thm}
\begin{proof}
    \begin{align*}
        \PP_b(\tau_a<\sigma_b)&=\sum_x p(b,x)\varphi(x)\\
        &=\sum_x \frac{C_{bx}\varphi(x)}{C_b}\\
        &=\sum_x \frac{I(b,x)}{C_b}\\
        &=\frac{1}{C_bR_{\text{eff}}}
    \end{align*}
\end{proof}

Nash-Williams Criterion

\subsection{Random Walks}


\section{Introduction to Random Walks}
\subsection{1D Simple Random Walk}
Let $S_n=\sum_{i=1}^{n}\xi_i$ where $\xi_i$'s are i.i.d. Rademacher random varaibles.
\paragraph{Reflection Principle}
\begin{Lem}
$\PP_0(\tau_i< n,S_n=i+j)=\PP_0(\tau_i< n,S_n=i-j)$
\end{Lem}
\begin{proof}
    Note that when $\tau_i<n$ and $S_n=i+j$, the trajectory must cross the line $i$. 
    Reflect the trajectory with respect to $i$ yields a trajectory which satisfies $\tau_i<n$ and $S_n=i-j$, and vice versa.
    Therefore a bijection between these two events is constructed. 
    Noting that the weights of all these trajectories induced by the probability distribution are equal.
\end{proof}
\begin{Rk}
    Note that $\PP_0(\tau_i< n,S_n=i+j)=\PP_0(S_n=i+j)$.
\end{Rk}

\begin{Thm}[Ballot Theorem]
    $\PP_0(\tau_i=n|S_n=i)=\frac{i}{n}$
\end{Thm}
\begin{proof}
    \begin{align*}
        \PP_0(\tau_i=n)&=\PP_0(S_n=i)-\PP_0(\tau_i<n,S_n=i)\\
                    &=\PP_0(S_n=i)-\frac{1}{2}\PP_0(\tau_i<n,S_{n-1}=i-1)-\frac{1}{2}\PP_0(\tau_i<n,S_{n-1}=i+1)\\
                    &=\PP_0(S_n=i)-\PP_0(\tau_i<n,S_{n-1}=i+1)\\
                    &=\PP_0(S_n=i)-\PP_0(S_{n-1}=i+1)\\
                    &=C_{n}^{\frac{n+i}{2}}\frac{1}{2^n}-C_{n-1}^{\frac{n+i}{2}}\frac{1}{2^{n-1}}\\
                    &=\frac{i}{n}C_{n}^{\frac{n+i}{2}}\frac{1}{2^n}\\
                    &=\frac{i}{n}\PP_0(S_n=i)
    \end{align*}
\end{proof}

\begin{Rk}
    Another interpretation of this result is that consider the trajectory of.
    The first time that it reaches 
    There is exactly $i$ such time. Therefore, 
\end{Rk}
\begin{Thm}
    $\PP_0(\tau_1>2n-1)=\PP_0(S_{2n}=0)$
\end{Thm}
\begin{proof}
    \begin{align*}
        \PP_0(\tau_1\leq 2n)&=\sum_i \PP_0(\tau_1\leq 2n,S_{2n}=i)\\
        &=\sum_{i\geq 1} \PP_0(\tau_1\leq 2n,S_{2n}=i)+\sum_{i\leq 0} \PP_0(\tau_1\leq 2n,S_{2n}=i)\\
        &=2\sum_{i\geq 1} \PP_0(S_{2n}=i)\\
        &=1-\PP_0(S_{2n}=0)
    \end{align*}
\end{proof}
\begin{Rk}
    $\PP_0(S_1\neq 0,\cdots,S_{2n}\neq 0)=\PP_0(S_{2n}=0)$
\end{Rk}

\begin{Thm}
    
\end{Thm}

\begin{Cor}
    $\PP_0(\tau_1<\infty)=1,\EE_0\tau_1=\infty$
\end{Cor}

\paragraph{Arcsin Laws}
Let $u_{2n}=\PP_0(S_{2n}=0)$. We first describe the arcsin law for the last visit to $0$.
\begin{Lem}
    Let $\sigma_{2n}=\sup\{m\leq 2n:S_m=0\} $. Then 
    \[\PP(\sigma_{2n}=2k)=u_{2k}u_{2n-2k} \] 
\end{Lem}
\begin{proof}
    $\PP(\sigma_{2n}=2k)=\PP(S_{2k}=0,S_{2k+1}\neq 0,\cdots,S_{2n}\neq 0)$.
\end{proof}

\begin{Thm}
    For $0<a<b<1$,
    \[ \PP_0(a\leq \frac{\sigma_{2n}}{2n}\leq b)\to \int_{a}^{b}\frac{1}{\pi}\frac{1}{\sqrt{x(1-x)}}\]
\end{Thm}
\begin{Cor}
    $\lim_{n\to\infty}\PP_0(S_r\neq 0 \quad\forall \delta n<r\leq n)=\frac{2}{\pi}\arcsin \sqrt{\delta}$
\end{Cor}

\begin{Rk}
    Anti-concentration Ineqaulity
\end{Rk}

Next, we prove the arcsin law for the time above 0.
\begin{Lem}
    Let $\pi_{2n}$ be the number of segments $(k-1,S_{k-1})\to (k,S_k)$ that lie above the axis, i.e. in $\{(x,y):y\geq 0\}$. Then 
    \[ \PP_0(\pi_{2n}=2k)=u_{2k}u_{2n-2k}. \]
\end{Lem}
\begin{Cor}
    For $0<a<b<1$,
    \[ \PP_0(a\leq \frac{\pi_{2n}}{2n}\leq b)\to \int_{a}^{b}\frac{1}{\pi}\frac{1}{\sqrt{x(1-x)}}\]
\end{Cor}

\paragraph{Maringale} Now we want to calculate the moments of $\tau$. Our method involves differentiating the exponential martingales.
For a simple random walk, 
\[Y_n(t):=\frac{e^{tS_n}}{(\cosh t)^n} \]
is a martingale. Thus its derivatives are also martingales.
\[\frac{\mathrm{d} Y_n(t)}{\mathrm{d} t}=\frac{e^{tS_n}}{(\cosh t)^{n+1}}(S_n\cosh t - n\sinh t)\]
so $\frac{\mathrm{d} Y_n(t)}{\mathrm{d} t}|_{t=0}=S_n$ is a martingale, as expected.
\[\frac{\mathrm{d}^2 Y_n(t)}{\mathrm{d} t^2}=\frac{e^{tS_n}}{(\cosh t)^{n+1}}((S_n^2-n)\cosh t - 2nS_n\sinh t)+n(n+1)\frac{e^{tS_n}\sinh^2t}{(\cosh t)^{n+2}} \]
so $\frac{\mathrm{d}^2 Y_n(t)}{\mathrm{d} t^2}|_{t=0}=S_n^2-n$ is a martingale, as expected.

\subsection{Lamplighter}

\begin{Eg}
    Consider
\end{Eg}

\paragraph{reversibility}

\paragraph{transience}

\paragraph{recurrence}



\section{Introduction to Branching Process}
\subsection{Galton-Watson Process}
Let $\{\xi_{ni}:n\geq 0,i\geq 0\}$ be a set of independent and identically-distributed natural number-valued random variables.
A Galton-Watson process is a stochastic process $\{X_n\}$ which evolves according to the recurrence formula $X_0 = 1$ and 
\[ X_{n+1}=\sum_{i=1}^{X_n}\xi_{ni}.\]
Our goal is to analysis the properties of this process.

\paragraph{Mean and Variance} As the Galton-Watson process is tree-like, it possesses many recurrence structure.
The first one we would utilize is the martingale property. We have 
\[\EE(X_{n+1}|\cF_n)=X_n\EE \xi ,\]
so that \[\frac{X_n}{(\EE \xi)^n}\]
is a martingale. By the property of martingales, we have 
\[\EE X_{n}=(\EE \xi)^n.\]
If we further assume that $\var \xi<\infty$, we can calculate the variance of $X_n$ similarly. 
We have
\begin{align*}
    \var (X_{n+1}) &= \var (\EE(X_{n+1}|\cF_n))+\EE \var(X_{n+1}|\cF_n)\\
    &=(\EE \xi)^2\var(X_n)+\EE X_n \var \xi\\
    &=(\EE \xi)^2\var(X_n)+(\EE \xi)^n \var \xi
\end{align*}
and we can solve this update formula by noting that $\var X_{1}=\var \xi $, which yields
\[\var X_{n}=\var \xi \sum_{i=n}^{2n-1} (\EE \xi)^n.\]

\paragraph{The Extinction Probability} The key quantity we are interested in is the
extinction probability (i.e. the probability of final extinction), which is given by
\[ \lim_{n\to\infty}\PP(X_n=0).\]
Note that once $X_n=0$, then $X_{n+k}=0$ for all $k\geq 1$, so $0$ is an absorbing state.



\paragraph{The Extinction Rate} $\frac{1}{n}$ by second moment method

\begin{Eg}
    Let $\xi\sim\text{Geo}(\frac{1}{2})$. Then $\PP(X_n \geq 1)=\frac{1}{n+1}$.
\end{Eg}
\begin{proof}
    The distribution of $X_n$ can be described by its generating function $f_{X_n}(s)=f^{(n)}(s)$
    where $f(s)=\frac{1}{2-s}$. So $f(0)=\frac{1}{2}$, $f^{(2)}(0)=\frac{2}{3}$, and $f^{(n)}=\frac{n}{n+1}$.
    Now $\PP(X_n=0)=f_{X_n}(0)=f^{(n)}(0)$, so $\PP(X_n \geq 1)=1-\PP(X_n = 0)=\frac{1}{n+1}$.
\end{proof}
\begin{Rk}
    Another view of this result.
    This is the probability that a simple random walk 
\end{Rk}

\subsection{Biased Random Walk on a Galton-Watson Tree}
Let $\QQ(\cdot)=\PP(\cdot||\TT|=\infty)$ be the measure conditioned on all Galton-Watson trees that survive.

Let $\eta$ be the (corresponds to $\xi$)
\[q_k=\sum_{l=0}^{\infty} p_{k+l} C_{k+l}^k \rho^{k-1}(1-\rho)^l \quad k\geq 1 \]


\[\frac{1}{R}=\sum_{i=1}^{\eta}\frac{1}{\lambda+\lambda R^{(i)}}\]
therefore $R=\infty$ if and only if $R^{(i)}=0$ $\forall i$.

\begin{Lem}[0-1 law]
    $\QQ(R=\infty)=0$ or $1$
\end{Lem}

\begin{Thm}
    When $\lambda\geq m$, recurrent
\end{Thm}



\begin{Thm}
    When $\lambda<m$, transient
\end{Thm}

\begin{Eg}[3-1 tree]
    
\end{Eg}

\paragraph{Precolation}

\section{Measurable Space Discrete Time Markov Chain}
Now we develop a more formal theory for discrete time Markov Chains by means of measure theory.
Let $(S,\mathcal{S})\to\mathbb{R}$ be a measurable space. This is the state space for our Markov chain.


\section{Discrete Space Continuous Time Markov Chain}

\begin{Def}[continuous-time random process]
    Let $I$ be a countable set. A continuous-time random process \[(X_t)_{t\geq 0}=(X_t:0\leq t\leq\infty)\] 
    with values in $I$ is a family of random variables $X_t:\Omega\to I$.
\end{Def}
We are going to consider ways in which we might specify the probabilistic behavior of $(X_t)_{t\geq 0}$.
To avoid uncountable union, we shall restrict our attention to processes $(X_t)_{t\geq 0}$ which are right-continuous.
\begin{Def}[right continuous]
    In the context of discrete space continuous time, a right-continuous process means $\forall \omega\in\Omega$
    and $t\geq 0$, $\exists \epsilon>0$ s.t. \[X_s(\omega)=X_t(\omega)\quad t\leq s\leq t+\epsilon\]
\end{Def}
\begin{Def}[increment]
    If $(X_t)_{t\geq 0}$ is a real-valued process, we can consider its increment $X_t-X_s$ over any interval $(s,t]$.
\end{Def}
\begin{Def}[stationary]
    We say that $(X_t)_{t\geq 0}$ has stationary increments if the distribution of $X_{s+t}-X_s$ depends only on $t\geq 0$.
\end{Def}
\begin{Def}[independent]
    We say that $(X_t)_{t\geq 0}$ has independent increments if its increments over amy finite collection of disjoint intervals are independent.
\end{Def}
\begin{Def}[$Q$-matrix]
    A $Q$-matrix on $I$ is a matrix $Q=(q_{ij}:i,j\in I)$ satisfying the following conditions:\newline
(i) $\forall i\quad 0\leq -q_{ii}<\infty$ \newline 
(ii) $\forall i\ne j\quad q_{ij}\geq 0$\newline 
(iii) $\forall i\quad \sum_{j\in I}q_{ij}=0$
\end{Def}

\subsection{Review: Properties of Exponential Distribution}
\begin{Def}
    
\end{Def}
\begin{Thm}[memoryless property]
    
\end{Thm}
\begin{Thm}[infimum]
    Let $I$ be a countable set and let $T_k\,k\in I$ be independent random variables with $T_k \sim E(q_k)$ and $0 < q := \sum_{k\in I} q_k < \infty$. 
    Set $T = \inf_k T_k$. Then this infimum is attained at a unique random value $K$ of $k$ a.s.. Moreover, $T$ and $K$ are independent, with $T \sim E(q)$ and $\PP(K = k) = \frac{q_k}{q}$.

\end{Thm}

\subsection{Poisson Process}

We begin with a definition of Poisson process in terms of jump chain and holding times, and then relate it to
the infinitesimal definition and transition probability definition.
\begin{Def}
    A right-continuous process $(X_t)_{t\leq 0}$ with values in $\mathbb{N}_{\geq 0}$ is a Poisson process of rate $\lambda\in (0,\infty)$
    if its holding times $S_1,S_2,\cdots$ are i.i.d. exponential random variables of mean $\lambda$ and its jump chain is given by $Y_n=n$.
\end{Def}

\begin{Thm}
    Let $(X_t)_{t\geq 0}$ be an increasing, right-continuous integer-valued process starting from $0$. Let $\lambda\in(0,\infty)$. TFAE:\newline 
    (i) (jump chain holding time definition) the holding times $S_1,S_2,\cdots$ of $(X_t)_{t\geq 0}$ are i.i.d. exponential random variables of mean $\lambda$ 
    and the jump chain is given by $Y_n=n$.\newline 
    (ii) (infinitesimal definition) $(X_t)_{t\geq 0}$ has independent increments and as $h\downarrow 0$, uniformly in $t$,
    \[\PP(X_{t+h}-X_t=0)=1-\lambda h+o(h),\quad \PP(X_{t+h}-X_t=1)=\lambda h+o(h)\]\newline 
    (iii) (incremental definition) $(X_t)_{t\geq 0}$ has stationary independent increments and for each $t$, $X_t$ has Poisson distribution of parameter $\lambda t$.
\end{Thm}

\begin{Thm}
    Let $(X_t)_{t\geq 0}$ be a Poisson process. Then, conditional on $(X_t)_{t\geq 0}$ having exactly one jump in the interval $[s, s +t]$, the time at which that jump occurs is uniformly distributed on $[s, s + t]$.
\end{Thm}
\begin{Thm}
    Let $(X_t)_{t\geq 0}$ be a Poisson process. Then, conditional on the event $\{X_t = n\}$, the jump times $J_1, \cdots ,J_n$ have joint density function
\[f(t_1,\cdots ,t_n)=n!1_{0\leq t_1\leq \cdots \leq t_n\leq t}\]
\end{Thm}
\begin{Rk}
    Thus, conditional on $\{X_t = n\}$, the jump times $J_1, \cdots ,J_n$ have the same distribution as an ordered sample of size $n$ from the uniform distribution on $[0,t]$.
\end{Rk}

\paragraph{An Approximation Scheme for Poisson Process} In the same spirit as Donsker's invariance principle,


\section{Continuous Time Martingale}
\subsection{Stopping Times}
\begin{Def}[stopping time]
    Let $\tau$ be a random time. If $\{\tau\leq t\}\in\mathcal{F}_t$ for every $t\geq 0$,
    then $\tau$ is called a stopping time.
\end{Def}
\begin{Def}[optional time]
    Let $T$ be a random time. If $\{T<t\}\in\mathcal{F}_t$ for every $t\geq 0$,
    then $T$ is called a stopping time.
\end{Def}
\begin{Lem}
    $T$ is an optional time of the filtration $\{\mathcal{F}_t\}$ if and only if it is a stopping time of the right-continuous
    filtration $\{\mathcal{F}_{t^+}\}$.
\end{Lem}
\begin{Cor}
    Every stopping time is optional, and the two concepts coincide if the filtration is right-continuous.
\end{Cor}
\begin{Lem}
    If $T$ is optional and $\theta$ is a positive constant, then $T+\theta$ is a stopping time.
\end{Lem}
\begin{Lem}
    If $\tau,\sigma$ are stopping times, then so are $\tau\wedge \sigma$, $\tau\vee \sigma$, $\tau+\sigma$.
\end{Lem}
\begin{proof}
    The first two assertions are trivial. \newline 
    For the third, start with the decomposition
\end{proof}
\begin{Lem}
    Let $T,S$ be optional times; then $T+S$ is optional. \newline
    Moreover, it is a stopping time if
\end{Lem}
\begin{Lem}
    Let $\{T_n\}_{n=1}^\infty$ be a sequence of optional times; then the random times 
    \[\sup_{n\geq 1}T_n\quad \inf_{n\geq 1}T_n\quad \limsup_{n\to\infty}T_n\quad \liminf_{n\to\infty}T_n \] 
    are all optional.\newline 
    Moreover, if the $T_n$'s are stopping times, then so is $\sup_{n\geq 1}T_n$.
\end{Lem}


\begin{Def}[$\sigma$-field of events determined prior to a stopping time]
    Let $\tau$ be a stopping time of the filtration $\{\mathcal{F}_t\}$. The $\sigma$-field of events determined prior to the stopping time $T$
    consists of those events $A\in\mathcal{F}$ for which $A\cap\{\tau\leq t\}\in \mathcal{F}_t$ for every $t\geq 0$.
\end{Def}
\begin{Lem}
    $\tau$ is $\mathcal{F}_\tau$-measurable.
\end{Lem}
\begin{proof}
    $\{\tau\leq t\}\cap\{\tau\leq t\}=\{\tau\leq t\}\in\mathcal{F}_t$, so $\{\tau\leq t\}\in \mathcal{F}_\tau$.
\end{proof}

\begin{Thm}
    For any two stopping time and $\tau,\sigma$ a random time s.t. $\sigma\leq \tau$ on $\Omega$, we have $\mathcal{F}_\sigma\subset\mathcal{F}_\tau$.
\end{Thm}
\begin{proof}
    For every stopping time $\tau$ and positive constant $t$, $\tau\wedge t$ is an $\mathcal{F}_t$-measurable random variable
    because $\mathcal{F}_{\tau\wedge t}\subset\mathcal{F}_t$. Therefore, $\{\sigma\wedge t\leq \tau\wedge t\}\in \mathcal{F}_t$.
    Then for any $A\in\mathcal{F}_\sigma$ we have $A\cap\{\sigma\leq \tau\}\in\mathcal{F}_\tau$, because
    \[ A\cap\{\sigma\leq \tau\}\cap \{\tau\leq t\}= (A\cap \{\sigma\leq t\})\cap \{\tau\leq t\}\cap \{\sigma\wedge t\leq \tau\wedge t\}\]
    Finally notice that $\{\sigma\leq \tau\}=\Omega$.
\end{proof}
\begin{Rk}
    We have proved a stronger result, namely
    for any $A\in\mathcal{F}_\sigma$ we have $A\cap\{\sigma\leq \tau\}\in\mathcal{F}_\tau$.
\end{Rk}
\begin{Thm}
    Let $\sigma$ and $\tau$ be stopping times. Then $\mathcal{F}_{\tau\wedge \sigma}=\mathcal{F}_\tau\cap\mathcal{F}_\sigma$.\newline 
    Moreover, $\{\tau<\sigma\}$, $\{\tau>\sigma\}$, $\{\tau\leq \sigma\}$, $\{\tau\geq \sigma\}$, $\{\tau=\sigma\}$ belongs to $\mathcal{F}_\tau\cap\mathcal{F}_\sigma$.
\end{Thm}
\begin{proof}
    From the above theorem, $\mathcal{F}_{\tau\wedge \sigma}\subset \mathcal{F}_{\tau}\cap\mathcal{F}_\sigma$.\newline 
    For $A\in \mathcal{F}_{\tau}\cap\mathcal{F}_\sigma$, $A\cap \{\tau\wedge \sigma\leq t\}=A\cap(\{\tau\leq t\}\cup\{\sigma\leq t\})\in\mathcal{F}_t$.
\end{proof}

\begin{Thm}
    Let $\tau,\sigma$ be stopping times and $X$ an integrable random variable. We have \newline 
    (i) $\EE(X|\mathcal{F}_\tau)=\EE(X|\mathcal{F}_{\sigma\wedge \tau})$ a.s. on $\{\tau\leq \sigma\}$.\newline 
    (ii) $\EE(\EE(X|\mathcal{F}_\tau)|\mathcal{F}_\sigma)=\EE(X|\mathcal{F}_{\sigma\wedge \tau})$ a.s..
\end{Thm}
\begin{proof}
    (i) Let $A\in\mathcal{F}_\tau$, then $A\cap \{\tau\leq \sigma\}$ belongs to both $\mathcal{F}_\tau$ and $\mathcal{F}_\sigma$, and therefore to $\mathcal{F}_\tau\cap\mathcal{F}_\sigma$. So 
    \[ \int_A 1_{\tau\leq \sigma} \EE(X|\mathcal{F}_{\tau\wedge\sigma})\mathrm{d}\PP=\int \EE(1_A1_{\tau\leq \sigma}X|\mathcal{F}_{\tau\wedge\sigma})\mathrm{d}\PP=\int_A1_{\tau\leq \sigma}X\mathrm{d}\PP\]
    (ii) On $\{\tau\leq\sigma\}$ we have $\EE(X|\mathcal{F}_\tau)=\EE(X|\mathcal{F}_{\sigma\wedge \tau})$ a.s. by (i), so 
    $\EE(\EE(X|\mathcal{F}_\tau)|\mathcal{F}_\sigma)=\EE(\EE(X|\mathcal{F}_{\sigma\wedge \tau})|\mathcal{F}_\sigma)=\EE(X|\mathcal{F}_{\sigma\wedge \tau})$. Similarly on
    $\{\sigma\leq \tau\}$ we have $\EE(\EE(X|\mathcal{F}_\tau)|\mathcal{F}_\sigma)=\EE(\EE(X|\mathcal{F}_\tau)|\mathcal{F}_{\sigma\wedge \tau})=\EE(X|\mathcal{F}_{\sigma\wedge \tau})$.
\end{proof}
\begin{Thm}
    Let $X=\{X_t,\mathcal{F}_t\}$ be a progressively measurable process, and let $\tau$ be a stopping time of the filtration $\mathcal{F}_t$.
    Then the random variable $X_\tau$ defined on $\{\tau<\infty\}$ is $\mathcal{F}_\tau$-measurable, and the stopped process 
    $\{X_{\tau\wedge t},\mathcal{F}_t\}$ is progressively measurable.
\end{Thm}



\subsection{From Discrete to Continuous}
In this subsection, we generalize inequalities and convergence results for discrete time martingales to continuous time martingales.\newline 
Let $X_t$ be a submartingale adapted to $\{\mathcal{F}_t\}$ whose paths are right-continuous. Let $[\sigma,\tau]$ be a subinterval of $[0,+\infty)$,
and let $a<b$, $\lambda>0$ be real numbers.
\begin{Thm}[Doob's inequality]
    Let $A=\left\{ \sup_{\sigma\leq t\leq \tau}X_t^+  \geq\lambda\right\}$, then \[\lambda \PP(A)\leq EX_\tau1_A\leq EX_\tau^+\]
\end{Thm}
\begin{proof}
    Let the finite set $\mathcal{S}$ consist of $\sigma,\tau$ and a finite subset of $[\sigma,\tau]\cap \mathbb{Q}$.

    By considering an increasing sequence $\{\mathcal{S}_n\}_{n=1}^\infty$ of finite sets whose union is the whole of $([\sigma,\tau]\cap \mathbb{Q})\cup\{\sigma,\tau\}$,
    we may replace $S$ by this union in the preceding discrete version of the inequality.
\end{proof}

\begin{Thm}[upcrossing inequality]
    \[(b-a)EU_{[\sigma,\tau]}\leq \EE(X_\tau-a)^+-\EE(X_\sigma-a)^+\]
\end{Thm}

\begin{Thm}[$L^p$ maximum inequality]
    $\bar{X}_\tau= \sup_{\sigma\leq t\leq \tau}X_t^+$, then for $1<p<\infty$, \[\EE(\bar{X}_\tau^p)\leq (\frac{p}{p-1})^pE(X_\tau^+)^p\]
\end{Thm}



For the remainder of this subsection, we deal only with right-continuous processes,
usually imposing no condition on the filtration $\mathcal{F}_t$.
\begin{Thm}[submartingale convergence]
    Assume $\sup_{t\geq 0} \EE(X_t^+)<\infty$. Then $X_\infty =\lim_{t\to\infty} X_t$ exists a.s., and $\EE|X_\infty|<\infty$.
\end{Thm}
\begin{proof}
    
\end{proof}

\begin{Thm}[optional sampling]
    Assume the submartingale has a last element $X_\infty$,
    and let $S\leq T$ be two optional times of the filtration. We have 
    \[ \EE(X_T|\mathcal{F}_{S^+})\geq X_S \quad \text{a.s.}\] 
    If $S$ is a stopping time, then $\mathcal{F}_S$ can replace $\mathcal{F}_{S^+}$ above.
\end{Thm}
\begin{proof}
    Consider the sequence of random times 
    \[S_n(\omega)=\left\{\begin{matrix}
        +\infty   & S(\omega )=+\infty \\
        \frac{k}{2^n}   & \frac{k-1}{2^n} \leq S(\omega )<\frac{k}{2^n} 
        \end{matrix}\right. \]
    and similarly defined sequences $\{T_n\}$. These are stopping times.
    For every fixed integer $n\geq 1$, both $S_n$ and $T_n$ take on a countable number of values and we also have $S_n\leq T_n$.
\end{proof}


\subsection{Doob-Meyer Decomposition}
\begin{Def}[increasing process]
    An adapted process $A$ is called increasing if for $\PP$-a.e. $\omega\in\Omega$ we have \newline 
    (i) $A_0(\omega)=0$\newline 
    (ii) $t\mapsto A_t(\omega)$ is a nondecreasing, right-continuous function, and $EA_t<\infty$ holds for every $t\in [0,\infty)$.\newline 
    An increasing process is called integrable if $EA_\infty<\infty$.
\end{Def}
\begin{Def}
    An increasing process $A$ is called natural if for every bounded, right-continuous martingale $\{M_t,\mathcal{F}_t;0\leq t<\infty\}$ we have
    \[ \EE\int_{(0,t]}M_s\mathrm{d}A_s=\EE\int_{(0,t]}M_{s^-}\mathrm{d}A_s\quad\forall 0<t<\infty\]
\end{Def}
\begin{Lem}
    If $A$ is an increasing process and $\{M_t,\mathcal{F}_t;0\leq t<\infty\}$ is a bounded right-continuous martingale, then 
    \[ \EE(M_tA_t)=\EE\int_{(0,t]}M_s\mathrm{d}A_s \]
\end{Lem}
The following concept is a strengthening of the notion of uniform integrablity for submartingales.
\begin{Def}[class DL]
    
\end{Def}
\begin{Thm}
    Let $\{\mathcal{F}_t\}$ satisfies the usual conditions. If the right-continuous submartingale $X=$ is of class DL,
    then it admits the decomposition as the summation if a right-continuous martingale
\end{Thm}

\subsection{Square Integrable Martingales}




\section{BM}
\begin{Def}[d-dimensional Brownian motion]
    A d-dimensional Brownian motion $B=(B_t)_{t\geq 0}$ is a stochastic process indexed by $[0,\infty)$ taking values in $\mathbb{R}^d$ s.t. \newline 
    (i) $B_0(\omega)=0$

\end{Def}

\subsection{Brownian Local Time}

\begin{Thm}
    There exists a stochastic process $\{L(t):t\geq 0\}$ called the local time at zero such that for all sequence $a_n\uparrow 0$ and $b_n\downarrow 0$ with 
    $a_n<b_n$, a.s.,
    \[\lim_{n\to\infty} 2(b_n-a_n)D(a_n,b_n,t)=L(t) \quad\forall t>0.\]
    Moreover, this process is almost surely locally $\gamma$-Holder continuous for any $\gamma<\frac{1}{2}$.
\end{Thm}

\begin{Thm}
    $\{L(t):t\geq 0\}\overset{d}{=}  \{M(t):t\geq 0\}$
\end{Thm}


\section{Stochastic Integration}
\subsection{}


\subsection{Martingale Characterization of BM}
\begin{Thm}[Levy]
    
\end{Thm}

\subsection{Representations of Martingales by BM}


\begin{Thm}[time-change for martingales]
    
\end{Thm}


\begin{Thm}[representation of square-integrable martingales by BM via Ito's integral]
    
\end{Thm}

\subsection{The Girsanov Theorem}


\section{The PDE Connection}




\section{Stochastic Differential Equations}




\section{Diffusions}

\subsection{Kolmogorov's Theory}


\subsection{Ito's theory}

\end{document}


In this section, we consider a discrete-time Markov chain with finite or countable state space.
\begin{Def}[$N$-Simplex]
The set $\mathscr{P}_\mathscr{X}$ is called the $N$-simplex, where $N$ is the cardinality of the state space $\mathscr{X}$:it 
is the subset of $\mathbb{R}^N$ gotten by intersecting the first orthant with the hyperplane consisting of all vectors whose entries sum to $1$.
\end{Def}
\begin{Thm}
The $N$-simplex $\mathscr{P}$ is a closed and bounded subset of $\mathbb{R}^N$.
Consequently, by the Heine-Borel Theorem, it is compact.
\end{Thm}

