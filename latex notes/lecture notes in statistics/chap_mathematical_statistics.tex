\chapter{Mathematical Statistics}

\section{Populations, Samples, and Models}
A typical statistical problem can be described ans follows:
\begin{enumerate}
\item (\textbf{planning experiments}) One or a series of random experiments is performed;
\item (\textbf{collecting data}) some data from the experiments are collected;
\item (\textbf{statistical analysis of the data}) extract information from the data, interpret the results, and draw some conclusions
\end{enumerate}
Statistical analysis of the data may contain:
\begin{itemize}
\item \textbf{descriptive data analysis}: such as the mean, median, range, standard deviation, etc., and some graphical displays, such as the histogram and box-and-whisker diagram, etc..
\item \textbf{statistical inference}
\item \textbf{decision theory}
\end{itemize}
We focus on more sophisticated methods of analyzing data, that is, the last two listed above.
\subsection{Populations and samples}
We formalize our statistics theory in the language of modern probability. First we need to specify some terms.
\begin{definition}[data set]
The data set is viewed as a \textbf{realization/observation} of a random element definitionined on a probability space ($\Omega,\mathcal{F},P$) related to the random experiment.
\end{definition}
\begin{definition}[population]
The probability measure $P$ is called the population.
\end{definition}
\begin{definition}[sample]
The random element that produces the data is called a \textbf{sample} from $P$. 
\end{definition}
\begin{definition}[known]
A population $P$ is known if and only if $P(A)$ is known for every event $A\in\mathcal{F}$.
\end{definition}
\subsection{Patametric and nonparametric models}
\begin{definition}[statistical model]
A statistical model is a set of assumptions on the population $P$ in a given problem. 
\end{definition}
\begin{remark}
It is often postulated to make the analysis possible or easy. Postulated models are often based on knowledge of the problem under consideration, and testing the correctness of them is also a task of statistical inference and decision theory.
\end{remark}
\begin{example}[parametric model]
The population $P$ is in a given parametric family $\mathcal{P}$.
\end{example}
\begin{example}[nonparametric model]
The population $P$ is in a given nonparametric family $\mathcal{P}$.
\end{example}
\begin{example}[semi-parametric model]
A nonparametric model having a parametric component.
\end{example}

\section{Statistics, Sufficiency, and Completeness}
\subsection{Statistics}
\begin{definition}[statistic]
A measurable function $T(X)$ of $X$ is called a statistic if $T$ is a known function.
\end{definition}
From a probabilistic point of view, the information within the statistic $T(X)$ is contained in the $\sigma-$field $\sigma(T(X))$. (This is because if two statistic generate the same $\sigma-$field, then there exist a bijection between them.) From this viewpoint, values of a statistic is non-material.\par
Any $T(X)$ is a random element. If the distribution of $X$ is unknown, then the distribution of $T(X)$ may also be unknown although $T$ is a known function. Finding the form of the distribution of $T(X)$ is one of the major problems in statistical inference and decision theory.
\subsection{Sufficiency and minimal sufficiency}
We now seek to describe a fully informative statistic $T(X)$. The concept definitionined below describes what we know by fully informative.
\begin{definition}[sufficiency]
Let $X$ be a sample from an unknown population $P\in\mathcal{P}$, where $\mathcal{P}$ is a family of populations. A statistics $T(X)$ is said to be sufficient for $P\in\mathcal{P}$ if and only if the conditional distribution of $X$ given $T$ is known (does not depend on $P$)
\end{definition}
\begin{remark}
The concept of syfficiency depends on the given family $\mathcal{P}$. If $T$ is sufficient for $P\in\mathcal{P}$, then $T$ is also sufficient for $P\in\mathcal{P}_0\subset\mathcal{P}$.
\end{remark}
This definitioninition can be interpreted as follows. Once we observe $X$ and compute a sufficient statistic $T(X)$, the original data $X$ do not contain any further information concerning the unknown population $P$ and can be discarded.\par
Finding a sufficient statistic in general involves a 'guess and verify' procedure. However, for families of populations having p.d.f's, a simple way of finding sufficient statistics is to use the factorization theorem.
\begin{theorem}[The factorization theorem]
Suppose that $X$ is a sample from $P\in\mathcal{P}$ and $\mathcal{P}$ is a family of probability measures on $(\mathbb{R}^n,\mathcal{B}^n)$ dominated by a $\sigma-$finite measure $\nu$. Then $T(X)$ is sufficient for $P\in\mathcal{P}$ if and only if there are nonnegative Borel functions $h$ (known) on $(\mathbb{R}^n,\mathcal{B}^n)$ and $g_P$ (unknown) on the range of $T$ such that
\[\frac{\mathrm{d} P}{\mathrm{d} \nu} =g_P(T(x))h(x)\]
\end{theorem}
For the proof of this theorem, we need a lemma concerning a family of probability measures.
\begin{lemma}
If a family $\mathcal{P}$ is dominated by a $\sigma-$finite measure, then $\mathcal{P}$ is dominated by a probability measure $Q=\sum_{i=1}^\infty c_iP_i$, where $c_i$'s are nonnegative constants with $\sum_{i=1}^\infty c_i=1$ and $P_i\in\mathcal{P}$.
\end{lemma}


Actually, there are many sufficient statistics for a given family $\mathcal{P}$, as the following theorem shows.
\begin{theorem}
If $T$ is a sufficient statistics and $T=\phi(S)$, where $\phi$ is measurable and $S$ is another statistics, then $S$ is sufficient.
\end{theorem}

\begin{remark}
Note that $\sigma(T)\subset\sigma(S)$ so $T$ provides a further reduction of the data than $S$.
\end{remark}
Therefore a question is raised. Is there a sufficient statistics that provides maximal reduction of the data?
\begin{definition}[minimal sufficiency]
Let $T$ be a sufficient statistic for $P\in\mathcal{P}$. $T$ is called a minimal sufficient statistic if and only if, for any other statistic $S$ sufficient for $P\in\mathcal{P}$, there is a measurable function $\phi$ such that $T=\phi(S)$ a.s. $\mathcal{P}$.
\end{definition}
\subsection{Completeness}
\begin{definition}[ancillary]
A statistic $V(X)$ is said to be ancillary if its distribution does not depend on the population $P$.
\end{definition}
\begin{definition}[first-order ancillary]
A statistic $V(X)$ is said to be first-order ancillary if $E[V(X)]$ is independent of $P$.
\end{definition}
Recalling the definitioninition of a complete orthogonal system in functional analysis, we definitionine the completeness of a statistic similarly. For a statistic $T(X)$, the measurable map $T:(\Omega,\mathcal{F})\longrightarrow(\mathcal{T},\mathcal{F}_\mathcal{T})$ induces a family of distributions $\mathcal{P}^T:=\left\{P\circ T^{-1}\right\}_{P\in\mathcal{P}}$ on $(\mathcal{T},\mathcal{F}_\mathcal{T})$. For $g:(\mathcal{T},\mathcal{F}_\mathcal{T})\longrightarrow(\mathbb{R},\mathcal{B})$ a $\mathcal{P}^T$ integrable Borel function, denote $\left\langle P,g\right\rangle_T:=E_P[g(T(X))]=\int_\mathcal{T}g\mathrm{d}P^T=P^T(g)$.
\begin{definition}[completeness]
A statistic $T(X)$ is said to be complete for $\mathcal{P}$ if and only if for any Borel function $g$ with $\left\langle P,g\right\rangle_T=0,\forall P\in\mathcal{P}$, we have $g=0$ a.s. $\mathcal{P}^T$.
\end{definition}
\begin{definition}[boundedly completeness]
A statistic $T(X)$ is said to be boundedly complete for $\mathcal{P}$ if and only if for any bounded Borel function $g$ with $\left\langle P,g\right\rangle_T=0,\forall P\in\mathcal{P}$, we have $g=0$ a.s. $\mathcal{P}^T$.
\end{definition}
\begin{remark}
If $T$ is (boundedly) complete and $S=\phi(T)$ for a measurable $\phi$, then $S$ is (boundedly) complete.
\end{remark}
\section{Statistical Decision Theory}
\subsection{Decision rules, loss functions, and risks}
Let $X$ be a sample from a population $P\in\mathcal{P}$. 
\begin{definition}[statistical decision]
A statistical decision is an \textbf{action} that one take after one observe $X$.
\end{definition}
\begin{definition}[action space]
Denote the set of allowable actions by $\mathbb{A}$. Let $\mathcal{F}_\mathbb{A}$ be a $\sigma$-field on $\mathbb{A}$. Then the measurable space $(\mathbb{A},\mathcal{F}_\mathbb{A})$ is called the action space.
\end{definition}
\begin{definition}[decision rule]
Let $\mathbf{X}$ be the range of $X$ and $\mathcal{F}_\mathbf{X}$ be a $\sigma$-field on $\mathbf{X}$. A decision rule is a known measurable function (a statistic) $T$ from $(\mathbf{X},\mathcal{F}_\mathbf{X})$ to $(\mathbb{A},\mathcal{F}_\mathbb{A})$.
\end{definition}
\begin{definition}[randomized decision rule]
A randomized decision rule is a function $\delta$ on $\mathbf{X}\times\mathcal{F}_\mathbb{A}$ s.t., for every $A\in\mathcal{F}_\mathbb{A}$ $\delta(\cdot,A)$ is a Borel function and, for every $x\in\mathbf{X}$ $\delta(x,\cdot)$ is a probability measure on $(\mathbb{A},\mathcal{F}_\mathbb{A})$.
\end{definition}
\begin{remark}
An alternate way to describe a randomized decision rule is to specify the method of \textbf{simulating} the action from $\mathbb{A}$ for each $x\in\mathbf{X}$.
\end{remark}
The construction or selection of decision rules cannot be done without any criterion about the performance of decision rules. In statistical decision theory, we set a criterion using a loss function.
\begin{definition}[loss function]
A loss function $L$ is a function from $\mathcal{P}\times\mathbb{A}$ to $[0,\infty)$ and is Borel on $(\mathbb{A},\mathcal{F}_\mathbb{A})$ for each fixed $P\in\mathcal{P}$.
\end{definition}
\begin{remark}
The loss function for a randomized rule $\delta$ is definitionined as \[L(P,\delta,x)=\int_\mathbb{A}L(P,a)\mathrm{d}\delta(x,a)\]
\end{remark}
A decision rule with small loss is preferred, but it is difficult to compare loss functions since they are random. For this reason, we introduce the risk function.
\begin{definition}[risk]
The risk of a decision rule $T$, which is the average loss for $T$, is definitionined to be \[ R_T(P)=E[L(P,T(X))]=\int_\mathbf{X}L(P,T(x))\mathrm{d}P_X(x)\]
\end{definition}
\begin{remark}
The risk of a randomized rule $\delta$ is definitionined as \[R_\delta(P)=E[L(P,\delta,X)]=\int_\mathbf{X}\int_\mathbb{A}L(P,a)\mathrm{d}\delta(x,a)\mathrm{d}P_X(x)\]
\end{remark}
\begin{definition}[as good as]
A rule $T_1$ is as good as another rule $T_2$ if and only if \[R_{T_1}(P)\le R_{T_2}(P) \text{   } \forall P\in\mathcal{P}\]
\end{definition}
\begin{remark}
If the inequality is strict for at least one $P\in\mathcal{P}$, we say $T_1$ is \textbf{better} than $T_2$.
\end{remark}
\begin{definition}[equivalent]
Two decision rules $T_1$ and $T_2$ are equivalent if and only if \[R_{T_1}(P)= R_{T_2}(P) \text{   } \forall P\in\mathcal{P}\]
\end{definition}
\begin{definition}[$\mathfrak{F}$-optimal]
Let $\mathfrak{F}$ be a class of decision rules. If there is a decision rule $T_*$ that is as good as any other rule in $\mathfrak{F}$, then $T_*$ is said to be $\mathfrak{F}$-optimal.
\end{definition}
\subsection{Admissibility and optimality}
Consider a given decision problem with a given loss $L(P,a)$.
\begin{definition}[admissibility]
Let $\mathfrak{F}$ be a class of decision rules. A decision rule $T\in\mathfrak{F}$ is called $\mathfrak{F}$-admissible if and only if there does not exist any $S\in\mathfrak{F}$ that is better than $T$.
\end{definition}

In view of the fact that an optimal rule often does not exist, statisticians adopt the following two approaches to choose a decision rule.\par
The first approach is to definitionine a class $\mathfrak{F}$ of decision rules that have some desirable properties and then try to find the best rule in $\mathfrak{F}$.
\begin{definition}[bias]
In an estimation problem, the bias of an estimator $T(X)$ of a real-valued parameter $\vartheta$ of the unknown population is definitionined to be $b_T(P)=E[T(X)]-\vartheta$. An estimator $T(X)$ is said to be unbiased for $\vartheta$ if and only if $b_T(P)=0$ for any $P\in\mathcal{P}$.
\end{definition}
\begin{definition}[invariance]

\end{definition}
The second approach is to consider some characteristic $R_T$ of $R_T(P)$ for a given decision rule $T$, and then minimize $R_T$ over $T\in\mathfrak{F}$.
\section{Statistical Inference}
In statisitical inference, we make an inference about the unknown population based on the sample $X$ and \textbf{inference procedure}, without using any loss function, although any inference procedure can be cast in decision-theoretic terms as a decision rule.\par
There are three main types of inference procedures: 
\begin{itemize}
\item \textbf{point estimators}
\item \textbf{hypothesis tests}
\item \textbf{confidence sets}
\end{itemize}
We will discuss them in the following sections.


\section{Asymptotic Criteria and Inference}
\subsection{Consistency}
\begin{definition}[consistency of point estimators]
Let $X=(X_1,\cdots,X_n)$ be a sample from $P\in\mathcal{P}$ and $T_n(X)$ be a point estimator of $\phi$ for every $n$.\par
(i) $T_n(X)$ is called consistent for $\phi$ if and only if $T_n(X)\to_p\phi$ w.r.t any $P\in\mathcal{P}$.\par
(ii) Let $\left\{a_n\right\}$ be a sequence of positive constants diverging to $\infty$. $T_n(X)$ is called $a_n$-consistent for $\phi$ if and only if $a_n[T_n(X)-\phi]=O_p(1)$ w.r.t. any $P\in\mathcal{P}$.\par
(iii) $T_n(X)$ is called strongly consistent for $\phi$ if and only if $T_n(X)\to\phi$ a.s. w.r.t. any $P\in\mathcal{P}$.\par
(iv) $T_n(X)$ is called $L_r$-consistent for $\phi$ if and only if $T_n(X)\to_{L_r}\phi$ w.r.t any $P\in\mathcal{P}$ for some fixed $r>0$.
\end{definition}
\begin{remark}
Consistency is actually a concept relating to a sequence of estimators.
\end{remark}

\subsection{Asymptotic Bias, Variance, and MSE}
\begin{definition}[asymptotic expectation]
Let $\xi,\xi_1,\xi_2,\cdots$ be random variables and $\left\{a_n\right\}$ be a sequence of positive numbers satisfying $a_n\to\infty$ or $a_n\to a>0$. If $a_n\xi_n\to_d\xi$ and $E\left|\xi\right|<\infty$, then $\frac{E\xi}{a_n}$ is called an asymptotic expectation of $\xi_n$.
\end{definition}
\begin{lemma}

\end{lemma}
\begin{theorem}[uniqueness of asymptotic expectation]
Let $\left\{\xi_n\right\}$ be a sequence of random variables. Suppose that both $\frac{E\xi}{a_n}$ and $\frac{E\eta}{b_n}$ are asymptotic expectations of $\xi_n$. Then one of the following three must hold:\par
(a) $E\xi=E\eta=0$;\par
(b) $E\xi\ne0,E\eta=0$, and $\frac{b_n}{a_n}\to0$; or $E\xi=0,E\eta\ne0$, and $\frac{a_n}{b_n}\to0$;\par
(c) $E\xi\ne0,E\eta\ne0$, and $\frac{\frac{E\xi}{a_n}}{\frac{E\eta}{b_n}}\to 1$.
\end{theorem}
\begin{proof}
According to the definitioninition, $a_n\xi_n\to_d\xi$ and $b_n\xi_n\to_d\eta$.\par
(i) If both $\xi$ and $\eta$ has a nondegenerate c.d.f's, then the result \par
(ii) Suppose that $\xi$ has a nondegenerate c.d.f. but $\eta$ is a constant. If $\eta\ne0$, then by Slusky's theorem $\frac{a_n}{b_n}\to \frac{\xi}{\eta}$, which is impossible since $\xi$ has a nondegenerate c.d.f..\par
(iii) Suppose that both $\xi$ and $\eta$ are constants. If $\xi=\eta=0$, the result follows. If $\xi\ne0$ and $\eta=0$, then $\frac{b_n}{a_n}\to 0$. If $\xi\ne0$ and $\eta\ne0$, then $\frac{b_n}{a_n}\to  \frac{\xi}{\eta}$.
\end{proof}

\subsection{Asymptotic Inference}
Statistical inference based on asymptotic criteria and approximations is called asymptotic statistical inference. We now focus on asymptotic hypothesis tests and confidence sets.
\begin{definition}
Let $X=(X_1,\cdots,X_n)$ be a sample from $P\in\mathcal{P}$ and $T_n(X)$ be a test for $H_0:P\in\mathcal{P}_0$ versus $H_1:P\in\mathcal{P}_1$.\par
(i) If $\limsup_n \alpha_{T_n}(P)\le \alpha$ for any $P\in\mathcal{P}_0$, then $\alpha$ is an asymptotic significance level of $T_n$.\par
(ii) If $\lim_{n\to\infty} \sup_{P\in\mathcal{P}_0}\alpha_{T_n}(P)$ exists, then it is called the limiting size of $T_n$.\par

\end{definition}
\section{Unbisaed Estimation}

\section{Estimation in Parametric Models}


\section{Hypothesis tests}

\section{Confidence sets}

